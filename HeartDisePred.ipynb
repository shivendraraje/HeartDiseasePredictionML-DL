{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8766f524-12a8-481c-9a34-add1c8d09019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Columns in dataset: Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n",
      "\n",
      "🔹 Updated Columns after Renaming: Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'AHD'],\n",
      "      dtype='object')\n",
      "\n",
      "✅ Features selected for training: Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'age*chol',\n",
      "       'trestbps*thalach'],\n",
      "      dtype='object')\n",
      "\n",
      "✅ Target variable: AHD\n",
      "\n",
      "🔹 Logistic Regression Performance:\n",
      "Accuracy: 0.7276264591439688\n",
      "F1 Score: 0.7388059701492538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       132\n",
      "           1       0.69      0.79      0.74       125\n",
      "\n",
      "    accuracy                           0.73       257\n",
      "   macro avg       0.73      0.73      0.73       257\n",
      "weighted avg       0.73      0.73      0.73       257\n",
      "\n",
      "\n",
      "🔹 Random Forest Performance:\n",
      "Accuracy: 0.9766536964980544\n",
      "F1 Score: 0.9754098360655737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       132\n",
      "           1       1.00      0.95      0.98       125\n",
      "\n",
      "    accuracy                           0.98       257\n",
      "   macro avg       0.98      0.98      0.98       257\n",
      "weighted avg       0.98      0.98      0.98       257\n",
      "\n",
      "\n",
      "🔹 SVM Performance:\n",
      "Accuracy: 0.6108949416342413\n",
      "F1 Score: 0.5726495726495726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       132\n",
      "           1       0.61      0.54      0.57       125\n",
      "\n",
      "    accuracy                           0.61       257\n",
      "   macro avg       0.61      0.61      0.61       257\n",
      "weighted avg       0.61      0.61      0.61       257\n",
      "\n",
      "\n",
      "🔹 XGBoost Performance:\n",
      "Accuracy: 0.9649805447470817\n",
      "F1 Score: 0.9626556016597511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       132\n",
      "           1       1.00      0.93      0.96       125\n",
      "\n",
      "    accuracy                           0.96       257\n",
      "   macro avg       0.97      0.96      0.96       257\n",
      "weighted avg       0.97      0.96      0.96       257\n",
      "\n",
      "\n",
      "🔹 KNN Performance:\n",
      "Accuracy: 0.7159533073929961\n",
      "F1 Score: 0.7181467181467182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       132\n",
      "           1       0.69      0.74      0.72       125\n",
      "\n",
      "    accuracy                           0.72       257\n",
      "   macro avg       0.72      0.72      0.72       257\n",
      "weighted avg       0.72      0.72      0.72       257\n",
      "\n",
      "\n",
      "🔹 Neural Network (MLP) Performance:\n",
      "Accuracy: 0.642023346303502\n",
      "F1 Score: 0.5964912280701754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       132\n",
      "           1       0.66      0.54      0.60       125\n",
      "\n",
      "    accuracy                           0.64       257\n",
      "   macro avg       0.65      0.64      0.64       257\n",
      "weighted avg       0.64      0.64      0.64       257\n",
      "\n",
      "\n",
      "✅ Model saved as best_ml_model.pkl\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6372 - loss: 0.6281 - val_accuracy: 0.7665 - val_loss: 0.4632\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.4459 - val_accuracy: 0.7782 - val_loss: 0.4316\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3852 - val_accuracy: 0.7665 - val_loss: 0.4277\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.3532 - val_accuracy: 0.7938 - val_loss: 0.4250\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3663 - val_accuracy: 0.7821 - val_loss: 0.4155\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3185 - val_accuracy: 0.7899 - val_loss: 0.4129\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.3244 - val_accuracy: 0.7938 - val_loss: 0.3945\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.3042 - val_accuracy: 0.7899 - val_loss: 0.4056\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2852 - val_accuracy: 0.8132 - val_loss: 0.3878\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.3137 - val_accuracy: 0.8093 - val_loss: 0.3898\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2473 - val_accuracy: 0.8210 - val_loss: 0.3814\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.2704 - val_accuracy: 0.8210 - val_loss: 0.3665\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2767 - val_accuracy: 0.8210 - val_loss: 0.3616\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.2857 - val_accuracy: 0.8249 - val_loss: 0.3500\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2534 - val_accuracy: 0.8327 - val_loss: 0.3441\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2321 - val_accuracy: 0.8249 - val_loss: 0.3325\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2419 - val_accuracy: 0.8482 - val_loss: 0.3229\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2409 - val_accuracy: 0.8366 - val_loss: 0.3242\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2322 - val_accuracy: 0.8444 - val_loss: 0.3158\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2389 - val_accuracy: 0.8366 - val_loss: 0.3183\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9378 - loss: 0.2081 - val_accuracy: 0.8482 - val_loss: 0.2939\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2036 - val_accuracy: 0.8521 - val_loss: 0.2834\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.1996 - val_accuracy: 0.8599 - val_loss: 0.2782\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.2228 - val_accuracy: 0.8638 - val_loss: 0.2647\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2083 - val_accuracy: 0.8677 - val_loss: 0.2596\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.1908 - val_accuracy: 0.8755 - val_loss: 0.2567\n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.2063 - val_accuracy: 0.8833 - val_loss: 0.2458\n",
      "Epoch 28/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9378 - loss: 0.1739 - val_accuracy: 0.8794 - val_loss: 0.2407\n",
      "Epoch 29/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.1862 - val_accuracy: 0.8949 - val_loss: 0.2287\n",
      "Epoch 30/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.1719 - val_accuracy: 0.8949 - val_loss: 0.2222\n",
      "Epoch 31/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9453 - loss: 0.1491 - val_accuracy: 0.9027 - val_loss: 0.2185\n",
      "Epoch 32/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1417 - val_accuracy: 0.8949 - val_loss: 0.2168\n",
      "Epoch 33/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.1665 - val_accuracy: 0.8911 - val_loss: 0.2183\n",
      "Epoch 34/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.1647 - val_accuracy: 0.8988 - val_loss: 0.2191\n",
      "Epoch 35/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1570 - val_accuracy: 0.9222 - val_loss: 0.1995\n",
      "Epoch 36/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.1333 - val_accuracy: 0.8988 - val_loss: 0.1934\n",
      "Epoch 37/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.1651 - val_accuracy: 0.9105 - val_loss: 0.1838\n",
      "Epoch 38/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.1016 - val_accuracy: 0.9339 - val_loss: 0.1772\n",
      "Epoch 39/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1482 - val_accuracy: 0.9455 - val_loss: 0.1704\n",
      "Epoch 40/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9440 - loss: 0.1464 - val_accuracy: 0.9300 - val_loss: 0.1783\n",
      "Epoch 41/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.1441 - val_accuracy: 0.9300 - val_loss: 0.1652\n",
      "Epoch 42/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1476 - val_accuracy: 0.9222 - val_loss: 0.1743\n",
      "Epoch 43/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1543 - val_accuracy: 0.9533 - val_loss: 0.1567\n",
      "Epoch 44/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.1678 - val_accuracy: 0.9377 - val_loss: 0.1482\n",
      "Epoch 45/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1344 - val_accuracy: 0.9455 - val_loss: 0.1450\n",
      "Epoch 46/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 0.1396 - val_accuracy: 0.9494 - val_loss: 0.1488\n",
      "Epoch 47/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.1571 - val_accuracy: 0.9494 - val_loss: 0.1478\n",
      "Epoch 48/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.1282 - val_accuracy: 0.9494 - val_loss: 0.1385\n",
      "Epoch 49/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1206 - val_accuracy: 0.9377 - val_loss: 0.1491\n",
      "Epoch 50/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9574 - loss: 0.1077 - val_accuracy: 0.9339 - val_loss: 0.1423\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.1450 \n",
      "\n",
      "✅ Deep Learning Model Accuracy: 0.9339\n",
      "\n",
      "✅ Model saved as heart_disease_dl_model.keras\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "# Import additional models\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import Deep Learning (TensorFlow/Keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load Data\n",
    "def load_data(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Error: File '{filepath}' not found. Please upload it.\")\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.columns = df.columns.str.strip()  # Remove extra spaces\n",
    "    print(\"\\n✅ Columns in dataset:\", df.columns)\n",
    "\n",
    "    # Rename 'target' to 'AHD' if needed\n",
    "    if 'target' in df.columns:\n",
    "        df.rename(columns={'target': 'AHD'}, inplace=True)\n",
    "\n",
    "    print(\"\\n🔹 Updated Columns after Renaming:\", df.columns)\n",
    "\n",
    "    if 'AHD' not in df.columns:\n",
    "        raise KeyError(\"Error: Target variable 'AHD' not found in dataset. Check column names.\")\n",
    "\n",
    "    # Drop rows where 'AHD' is NaN\n",
    "    df = df.dropna(subset=['AHD'])\n",
    "\n",
    "    # Ensure 'AHD' is numeric\n",
    "    df['AHD'] = pd.to_numeric(df['AHD'], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_data(df):\n",
    "    if 'thal' in df.columns:\n",
    "        if not df['thal'].mode().empty:\n",
    "            df['thal'] = df['thal'].fillna(df['thal'].mode()[0])\n",
    "        else:\n",
    "            df['thal'] = df['thal'].fillna(2)  # Default category\n",
    "\n",
    "    if 'cp' in df.columns:\n",
    "        df['cp'] = df['cp'].map({'typical': 0, 'asymptomatic': 1, 'nonanginal': 2, 'nontypical': 3})\n",
    "\n",
    "    # Handle missing values\n",
    "    if 'ca' in df.columns:\n",
    "        df['ca'] = df['ca'].fillna(df['ca'].mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    if all(col in df.columns for col in ['age', 'chol']):\n",
    "        df['age*chol'] = df['age'] * df['chol']\n",
    "    if all(col in df.columns for col in ['trestbps', 'thalach']):\n",
    "        df['trestbps*thalach'] = df['trestbps'] * df['thalach']\n",
    "    return df\n",
    "\n",
    "# Train ML Models\n",
    "def train_models(x_train, x_test, y_train, y_test):\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    x_train_imputed = imputer.fit_transform(x_train)\n",
    "    x_train = pd.DataFrame(x_train_imputed, columns=x_train.columns[:x_train_imputed.shape[1]])\n",
    "\n",
    "    x_test_imputed = imputer.transform(x_test)\n",
    "    x_test = pd.DataFrame(x_test_imputed, columns=x_test.columns[:x_test_imputed.shape[1]])\n",
    "\n",
    "    # Feature Selection\n",
    "    selector = SelectKBest(score_func=f_classif, k=10)\n",
    "    x_train = selector.fit_transform(x_train, y_train)\n",
    "    x_test = selector.transform(x_test)\n",
    "\n",
    "    # Apply PCA (Reduce to 5 Features)\n",
    "    pca = PCA(n_components=5)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    x_test = pca.transform(x_test)\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "        \"SVM\": SVC(kernel=\"rbf\", probability=True),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"Neural Network (MLP)\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_f1 = 0\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        f1 = f1_score(y_test, pred)\n",
    "\n",
    "        print(f\"\\n🔹 {name} Performance:\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "        print(\"F1 Score:\", f1)\n",
    "        print(classification_report(y_test, pred))\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model = model\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Train Deep Learning Model\n",
    "def train_deep_learning_model(x_train, x_test, y_train, y_test):\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    x_train = imputer.fit_transform(x_train)\n",
    "    x_test = imputer.transform(x_test)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, activation=\"relu\", input_shape=(x_train.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=50, batch_size=16, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"\\n✅ Deep Learning Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Save Model\n",
    "def save_model(model, filename):\n",
    "    if isinstance(model, tf.keras.Model):\n",
    "        filename = filename if filename.endswith((\".keras\", \".h5\")) else filename + \".keras\"\n",
    "        model.save(filename)\n",
    "    else:\n",
    "        joblib.dump(model, filename)\n",
    "    print(f\"\\n✅ Model saved as {filename}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = \"Heart_dataset.csv\"\n",
    "\n",
    "    try:\n",
    "        df = load_data(csv_file)\n",
    "        df = preprocess_data(df)\n",
    "        df = feature_engineering(df)\n",
    "\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        x = df.drop(columns=['AHD'])\n",
    "        y = df['AHD']\n",
    "\n",
    "        print(\"\\n✅ Features selected for training:\", x.columns)\n",
    "        print(\"\\n✅ Target variable:\", y.name)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75, random_state=42)\n",
    "\n",
    "        # Train ML models\n",
    "        best_ml_model = train_models(x_train, x_test, y_train, y_test)\n",
    "        save_model(best_ml_model, \"best_ml_model.pkl\")\n",
    "\n",
    "        # Train Deep Learning Model\n",
    "        best_dl_model, history = train_deep_learning_model(x_train, x_test, y_train, y_test)\n",
    "        save_model(best_dl_model, \"heart_disease_dl_model.keras\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n⚠️ Full Error Message:\", repr(e))\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198e6fc-8579-45c2-92c9-bf68ca0449a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
